# 研究戦略と次期最適化提案

## 目次
1. [現状分析](#1-現状分析)
2. [性能ボトルネックの詳細分析](#2-性能ボトルネックの詳細分析)
3. [候補最適化手法の評価](#3-候補最適化手法の評価)
4. [推奨アプローチ](#4-推奨アプローチ)
5. [実装ロードマップ](#5-実装ロードマップ)
6. [論文構成案](#6-論文構成案)

---

## 1. 現状分析

### 1.1 達成済みの成果

✅ **Tier 1 (Baseline JIT)**
- 基本ブロック単位のJITコンパイル
- Global Dispatch方式による遅延コンパイル
- Basic Block Versioning (BBV)による型特殊化

✅ **Tier 2 (Trace Linearization)**
- ホットパスの検出
- 複数BBの線形化とインライン展開
- 制御フローオーバーヘッドの大幅削減
- **一部ベンチマークでAOT超え達成**

### 1.2 残存する課題

❌ **データアクセス**: 40-50%のオーバーヘッド
- オブジェクトフィールドアクセス
- 配列要素アクセス
- 型タグチェック・型変換

❌ **関数呼び出し**: 30-40%のオーバーヘッド
- 高階関数の間接呼び出し
- クロージャ生成
- 引数の型チェック

❌ **その他**: 10-20%
- ガベージコレクション
- 動的ディスパッチ

### 1.3 パフォーマンス目標

| 項目 | 現状 | 目標 |
|------|------|------|
| 全体平均 | AOTの1.5倍遅い | AOTと同等以上 |
| ピーク性能 | 一部でAOT超え | 多数でAOT超え |
| ウォームアップ | 良好 | 維持 |

---

## 2. 性能ボトルネックの詳細分析

### 2.1 データアクセスのボトルネック

#### 問題1: 動的型チェック

**現在のコード**:
```wasm
;; オブジェクトから整数を取り出す
(local.get $obj)
(struct.get $obj $tag)  ;; 型タグをチェック
(i32.const 1)           ;; INT_TAG
(i32.ne)
(if (then (unreachable)))  ;; 型エラー
(local.get $obj)
(struct.get $obj $data) ;; データ取得
(i64.reinterpret_f64)   ;; 型変換
```

**コスト**: 型チェック + 複数回のメモリアクセス

#### 問題2: オブジェクト表現のオーバーヘッド

**Boxed表現**:
```
Object {
  tag: i32,      // 4 bytes
  data: anyref   // ポインタ
}
```

**理想**: 可能な限りunboxed（i64直値）で扱う

#### 問題3: 配列アクセス

**現在**:
```scheme
(vector-ref vec 0)
```
↓
```wasm
;; bounds check
;; 型チェック
;; array.get
```

**コスト**: 境界チェック + 型チェック + 間接アクセス

### 2.2 関数呼び出しのボトルネック

#### 問題1: 高階関数の間接呼び出し

**現在のコード**:
```scheme
(define (map f lst)
  (if (null? lst)
      '()
      (cons (f (car lst))          ;; ← 間接呼び出し
            (map f (cdr lst)))))
```

**コスト**:
1. クロージャオブジェクトからfuncrefを取得
2. funcrefを経由した間接呼び出し
3. 引数の型チェック
4. 結果の型チェック

#### 問題2: クロージャ生成

**現在**:
```scheme
(lambda (x) (+ x captured-var))
```
↓
```wasm
;; Closureオブジェクトの割り当て
;; captured-varのコピー
;; エントリポイントテーブルの設定
```

**コスト**: ヒープ割り当て + 初期化コスト

---

## 3. 候補最適化手法の評価

### 3.1 Polymorphic Inline Caching (PIC)

#### 概要
呼び出しサイトで観測された型情報をキャッシュし、型チェックを高速化。

#### メリット
- ✅ 高階関数呼び出しの高速化
- ✅ 実装が比較的容易
- ✅ V8/SpiderMonkeyで実績あり
- ✅ 論文の「目玉」になりうる（Wasm上でのPIC実装は新規性高い）

#### デメリット
- ⚠️ メモリオーバーヘッド（キャッシュエントリ）
- ⚠️ ポリモーフィズム度が高いと効果薄

#### 実装の複雑さ
🟢 中程度（2-3週間）

#### 期待効果
📈 関数呼び出しコスト 30-50% 削減

---

### 3.2 Escape Analysis & Stack Allocation

#### 概要
オブジェクトのエスケープ解析により、ヒープではなくスタックに割り当て。

#### メリット
- ✅ クロージャ生成コストの削減
- ✅ GC圧力の軽減
- ✅ 一時オブジェクトの最適化

#### デメリット
- ❌ Wasm GCではスタック割り当て不可（現状）
- ❌ 解析の複雑さ
- ⚠️ 効果が限定的（エスケープしないオブジェクトは少ない）

#### 実装の複雑さ
🔴 高（4-6週間）

#### 期待効果
📈 クロージャ生成コスト 20-30% 削減（限定的）

---

### 3.3 Speculative Optimization + Deoptimization

#### 概要
仮定（例: 型が常にInt）に基づいて最適化し、仮定が破れたらdeoptimize。

#### メリット
- ✅ 大幅な高速化の可能性
- ✅ 動的言語JITの王道アプローチ
- ✅ 型チェックの削減

#### デメリット
- ❌ Deoptimizationの実装が非常に複雑
- ❌ Wasmでのスタックフレーム操作に制約
- ⚠️ オーバースペキュレーションのリスク

#### 実装の複雑さ
🔴 非常に高（6-8週間以上）

#### 期待効果
📈 全体で 40-60% 高速化の可能性（ただしリスク高）

---

### 3.4 Type Feedback & Adaptive Compilation

#### 概要
ランタイム型情報を収集し、頻出する型パターンに特殊化。

#### メリット
- ✅ データアクセスの最適化
- ✅ 型チェックの削減
- ✅ BBVの拡張として自然

#### デメリット
- ⚠️ プロファイリングオーバーヘッド
- ⚠️ コードサイズの増加

#### 実装の複雑さ
🟡 中〜高（3-5週間）

#### 期待効果
📈 データアクセスコスト 25-40% 削減

---

### 3.5 Object Shape Analysis (Hidden Classes)

#### 概要
V8のHidden Classライクな仕組みで、オブジェクト構造を推論。

#### メリット
- ✅ フィールドアクセスの最適化
- ✅ 型推論の強化

#### デメリット
- ❌ Schemeではオブジェクトが少ない（cons cellが主）
- ❌ Wasm GCの制約
- ⚠️ 実装が複雑

#### 実装の複雑さ
🔴 高（5-7週間）

#### 期待効果
📈 限定的（Schemeの特性上）

---

### 3.6 Partial Evaluation

#### 概要
部分評価により、静的に決まる計算を事前実行。

#### メリット
- ✅ 定数畳み込みの拡張
- ✅ 特殊化の強化

#### デメリット
- ⚠️ 既存の定数伝搬と重複
- ⚠️ 効果が限定的

#### 実装の複雑さ
🟡 中（2-4週間）

#### 期待効果
📈 10-20% 局所的改善

---

## 4. 推奨アプローチ

### 4.1 第一推奨: Polymorphic Inline Caching (PIC)

#### 理由
1. **実装可能性**: 2-3週間で実装可能
2. **効果**: 高階関数が多いSchemeでは大きな効果
3. **新規性**: Wasm上でのPIC実装は新しい
4. **論文の目玉**: 既存のTrace Linearizationと組み合わせて強力
5. **実績**: V8/SpiderMonkeyで確立された手法

#### 実装戦略

**Phase 1: モノモーフィックIC (1週間)**
- 単一の型パターンのみキャッシュ
- 型一致で直接呼び出し

**Phase 2: ポリモーフィックIC (1週間)**
- 複数の型パターンをキャッシュ（2-4個）
- 型ごとに分岐

**Phase 3: メガモーフィック対策 (1週間)**
- 多態度が高い場合の最適化
- ハッシュテーブルベースの高速ルックアップ

#### 期待される成果
- 関数呼び出し: 30-50% 高速化
- 全体平均: 15-25% 高速化
- **AOTコンパイラと同等またはそれ以上の性能**

---

### 4.2 第二推奨（併用可能）: Type Feedback & Adaptive Compilation

#### 理由
1. PICと相補的
2. データアクセスの最適化に有効
3. 既存のBBVインフラを活用

#### 実装戦略

**Phase 1: 型プロファイル収集 (1週間)**
- ランタイムでの型観測
- 頻出型パターンの記録

**Phase 2: 型特殊化コンパイル (2週間)**
- 頻出型に特化したコード生成
- 型チェックの削減

**Phase 3: 適応的再コンパイル (1週間)**
- 型パターン変化時の再最適化

#### 期待される成果
- データアクセス: 25-40% 高速化
- 全体平均: さらに10-15% 改善

---

### 4.3 実装の優先順位

```
Priority 1 (必須): Polymorphic Inline Caching
  ├─ Week 1-2: 基本実装
  ├─ Week 3: ベンチマーク・調整
  └─ Week 4: 論文執筆開始

Priority 2 (推奨): Type Feedback
  ├─ Week 5-6: プロファイル収集
  ├─ Week 7-8: 型特殊化
  └─ Week 9: 統合・評価

Priority 3 (オプション): その他の改善
  └─ 時間に余裕があれば
```

---

## 5. 実装ロードマップ

### 5.1 Week 1-2: PIC基本実装

**タスク**:
- [ ] IR命令の拡張 (`CallClosurePIC`)
- [ ] PICマネージャーの実装
- [ ] プロファイリングAPIの追加
- [ ] モノモーフィックICのコード生成
- [ ] ランタイムサポート

**成果物**:
- 動作するPIC実装（モノモーフィック）
- ユニットテスト

### 5.2 Week 3: ポリモーフィックIC

**タスク**:
- [ ] 複数型パターンのキャッシュ
- [ ] 型チェック分岐の最適化
- [ ] メガモーフィック検出

**成果物**:
- 完全なPIC実装
- ベンチマーク結果

### 5.3 Week 4: 評価・調整

**タスク**:
- [ ] 各種ベンチマークでの評価
- [ ] パフォーマンスチューニング
- [ ] ドキュメント整備

**成果物**:
- パフォーマンスレポート
- 論文用データ

### 5.4 Week 5-9: Type Feedback（オプショナル）

**タスク**:
- [ ] 型プロファイル収集機構
- [ ] 適応的再コンパイル
- [ ] 統合評価

**成果物**:
- さらなる性能向上
- 追加の論文データ

---

## 6. 論文構成案

### 6.1 タイトル案

**Option 1**: "Efficient Dynamic JIT Compilation for Scheme on WebAssembly: Combining Trace Linearization with Polymorphic Inline Caching"

**Option 2**: "High-Performance Scheme JIT Compiler for WebAssembly using Multi-Tier Optimization"

### 6.2 構成

#### 1. Introduction
- 動的言語のWasm上での課題
- 既存のAOTコンパイラとの比較
- 本研究の貢献

#### 2. Background
- WebAssembly GC
- R5RS Scheme
- 従来のJIT技術

#### 3. System Architecture
- 2-Tier JITシステム
- Global Dispatch機構
- Basic Block Versioning

#### 4. Tier 1: Baseline JIT
- 遅延コンパイル
- BBV
- 実装詳細

#### 5. Tier 2: Trace Linearization ⭐
- ホットパス検出
- 線形化アルゴリズム
- Promotion機構
- **性能評価**

#### 6. Tier 2+: Polymorphic Inline Caching ⭐⭐
- **PICの設計** ← 新規貢献
- **Wasm上での実装課題**
- **型キャッシュ戦略**
- **モノ/ポリ/メガモーフィック処理**
- **性能評価** ← 目玉

#### 7. Evaluation
- ベンチマーク設定
- AOTコンパイラとの比較
- **各最適化の寄与度分析**
- ウォームアップ時間
- メモリ使用量

#### 8. Related Work
- TraceMonkey、LuaJIT
- V8、SpiderMonkey
- 他のWasmベースJIT

#### 9. Conclusion
- 達成した性能
- 今後の課題

### 6.3 重要な評価項目

**必須**:
- [ ] Trace Linearization単独の効果
- [ ] PIC単独の効果
- [ ] 両方の組み合わせ効果
- [ ] AOTコンパイラとの比較
- [ ] ウォームアップ時間

**推奨**:
- [ ] 各ベンチマークでの詳細分析
- [ ] PICヒット率の測定
- [ ] コードサイズの比較
- [ ] メモリ使用量

---

## 7. リスク管理

### 7.1 技術的リスク

| リスク | 影響 | 対策 |
|--------|------|------|
| PIC効果が期待以下 | 高 | 早期プロトタイプで検証 |
| Wasmの制約 | 中 | 事前調査、代替案準備 |
| 実装遅延 | 中 | マイルストーン管理 |

### 7.2 スケジュールリスク

**Worst Case** (PICのみ):
- 4週間でPIC実装完了
- AOTと同等性能達成
- 論文として最低限の成果

**Best Case** (PIC + Type Feedback):
- 9週間で両方実装
- AOTを20-30%超える性能
- 強力な論文

### 7.3 フォールバックプラン

**Plan B**: PICが期待通りでない場合
- Type Feedbackに注力
- Speculative Optimizationの一部実装
- 複数の小さな最適化の組み合わせ

---

## 8. 結論

### 8.1 推奨する次のステップ

1. **Polymorphic Inline Caching の実装** （最優先）
   - 実装可能性: 高
   - 効果: 大
   - 新規性: 高
   - 論文の目玉になる

2. **Type Feedback の追加実装** （時間があれば）
   - 相補的な効果
   - さらなる性能向上

3. **徹底的な評価**
   - 各最適化の寄与度を明確化
   - AOTコンパイラとの詳細比較

### 8.2 期待される最終成果

- **性能**: AOTコンパイラと同等以上
- **論文**: Trace Linearization + PIC の組み合わせという新規性
- **実用性**: 実際に使えるScheme JITコンパイラ

### 8.3 次のアクション

```bash
# 1. PIC実装の開始
git checkout -b feature/polymorphic-inline-caching

# 2. IR拡張
vim webschembly-compiler-crates/ir/src/lib.rs

# 3. PICマネージャー実装
vim webschembly-compiler/src/jit/pic.rs

# 4. テストケース作成
vim webschembly-js/fixtures/pic_test.scm
```

---

**この戦略で進めることで、論文として十分なインパクトと技術的貢献が達成できます。**
